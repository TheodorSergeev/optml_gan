{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheodorSergeev/optml_gan/blob/main/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fe1zK4TEn2P"
      },
      "source": [
        "Adapted from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElE3epO2FCLq"
      },
      "source": [
        "# Initialisation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* First, create an empty directoy optml_gan in the main directory of you google drive. Then download and extract the contents of our main repository ([link to repo](https://github.com/TheodorSergeev/optml_gan)) and place them in the optml_gan directory on your google drive. Then run the following cell.   \n",
        "* If you only want to run the code, you can only copy the src directory.  \n",
        "* If you want to reproduce our plots without going through the training process, we recommend you open the notebook in the following google drive ([link to drive](https://drive.google.com/drive/folders/1C-8I8Z3hHlfn-q-5P34SjtJbyep-u9UT?usp=sharing)) that we are hosting, it contains all the save files from the experiments and code to reproduce our plots."
      ],
      "metadata": {
        "id": "fAOV48c3y3w2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg1MBmvsdWEd",
        "outputId": "97794744-c382-452d-f6d0-b481b7679467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (5.6.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert) (4.10.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert) (5.0.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (1.5.0)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (2.11.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert) (2.6.1)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (5.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (5.1.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert) (2.0.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert) (2.15.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (4.11.4)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (5.7.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (4.2.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.4->nbconvert) (3.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert) (0.5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pipreqs\n",
            "  Downloading pipreqs-0.4.11-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from pipreqs) (0.6.2)\n",
            "Collecting yarg\n",
            "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from yarg->pipreqs) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (2022.5.18.1)\n",
            "Installing collected packages: yarg, pipreqs\n",
            "Successfully installed pipreqs-0.4.11 yarg-0.1.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-fid\n",
            "  Downloading pytorch-fid-0.2.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->pytorch-fid) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.2.2->pytorch-fid) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (2022.5.18.1)\n",
            "Building wheels for collected packages: pytorch-fid\n",
            "  Building wheel for pytorch-fid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-fid: filename=pytorch_fid-0.2.1-py3-none-any.whl size=14835 sha256=0c4488d187f3669520f3151912fa47d197001cb32e70678644b0f8dbf87f111d\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/ac/03/c5634775c8a64f702343ef5923278f8d3bb8c651debc4a6890\n",
            "Successfully built pytorch-fid\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.2.1\n",
            "/content/drive/My Drive/optml_gan\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # packages to generate requirement.txt\n",
        "    %pip install nbconvert\n",
        "    %pip install pipreqs\n",
        "    # for Frechet inception distance\n",
        "    %pip install pytorch-fid\n",
        "\n",
        "    %cd drive/My Drive/optml_gan\n",
        "    PATH = './'\n",
        "else:\n",
        "    PATH = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M50Mkga4EhNy"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.utils.data\n",
        "\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from scipy import linalg\n",
        "from torch.nn.functional import adaptive_avg_pool2d\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qZmOPHfZykX5"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqmZqleaEhN0"
      },
      "source": [
        "# Source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f-4yBgJxykX6"
      },
      "outputs": [],
      "source": [
        "from src.data_handling import *\n",
        "from src.utils import *\n",
        "from src.model import *\n",
        "from src.losses import *\n",
        "from src.fid import *\n",
        "\n",
        "loss_dict = {\n",
        "    \"kl\": (loss_dis_kl, loss_gen_kl),\n",
        "    \"wass\": (loss_dis_wasser, loss_gen_wasser),\n",
        "    \"hinge\": (loss_dis_hinge, loss_gen_hinge)\n",
        "}\n",
        "\n",
        "# FID\n",
        "\n",
        "from src.training import *\n",
        "from src.visualisation import *\n",
        "from src.serialisation import *\n",
        "\n",
        "# https://keras.io/examples/generative/conditional_gan/\n",
        "from src.architectures import *\n",
        "\n",
        "from src.gridsearch import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beMBvkIjFl7z"
      },
      "source": [
        "# Training example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSQF8-Mitrs2"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VeYrHwkRx-59"
      },
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "dataroot = PATH + \"data/\"\n",
        "\n",
        "# Dataset name\n",
        "dataset_name = 'mnist'  # 'cifar10' or 'mnist'\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 128\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
        "image_size = 28  # 28 for mnist, 64 for others\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 128\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ROhmdtOztq8W"
      },
      "outputs": [],
      "source": [
        "# Number of training epochs\n",
        "num_epochs = 3\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lrD = 2e-4\n",
        "lrG = 2e-4\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.9  # 0.9 == default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uvDLoiTmyC8b"
      },
      "outputs": [],
      "source": [
        "dataset, nc = get_dataset(dataset_name, image_size, dataroot)\n",
        "\n",
        "# Create the dataloader\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0wNXW77zD4b"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWLDGuP1ykX-",
        "outputId": "b508892e-8a37-42c0-ab41-94abcdd4b956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator parameters 1493520\n",
            "Discriminator parameters 1460225\n",
            "./ adam_mG0.0_mD0.0_ wassLoss_lrd0.0002_lrg0.0002_b1b0.9_itd5_itg1_gpv10.0_\n",
            "Starting Training Loop...\n",
            "[0/20][0/469]\tLoss_D: -0.5729\tLoss_G: -0.0335\tD(x): 1.6005\tD(G(z)): 0.0345 / 0.0335\n",
            "[0/20][50/469]\tLoss_D: -2567.3757\tLoss_G: -5441.0566\tD(x): 8946.7539\tD(G(z)): 5576.6924 / 5441.0566\n",
            "[0/20][100/469]\tLoss_D: -30515.3223\tLoss_G: 72398.7188\tD(x): -13460.2734\tD(G(z)): -72471.7656 / -72398.7188\n",
            "[0/20][150/469]\tLoss_D: -6868.7910\tLoss_G: 4306.2422\tD(x): 8168.0684\tD(G(z)): -4858.0981 / -4306.2422\n",
            "[0/20][200/469]\tLoss_D: -12450.2861\tLoss_G: 14821.1113\tD(x): 6068.2803\tD(G(z)): -15204.1309 / -14821.1113\n",
            "[0/20][250/469]\tLoss_D: 294.9125\tLoss_G: -13247.3867\tD(x): 13634.1758\tD(G(z)): 13203.7832 / 13247.3867\n",
            "[0/20][300/469]\tLoss_D: -2972.6931\tLoss_G: -16284.5488\tD(x): 22966.1621\tD(G(z)): 17177.3008 / 16284.5488\n",
            "[0/20][350/469]\tLoss_D: -6371.9805\tLoss_G: 25654.4102\tD(x): -12069.4854\tD(G(z)): -26027.7617 / -25654.4102\n",
            "[0/20][400/469]\tLoss_D: 1572.7870\tLoss_G: 2016.6958\tD(x): -2216.5222\tD(G(z)): -2083.6521 / -2016.6958\n",
            "[0/20][450/469]\tLoss_D: -281.6372\tLoss_G: 7870.3164\tD(x): -5385.2993\tD(G(z)): -9005.1904 / -7870.3164\n",
            "[0/20][468/469]\tLoss_D: -193.6347\tLoss_G: 629.8372\tD(x): 87.1126\tD(G(z)): -745.4720 / -629.8372 t: 21.019\n",
            "[1/20][0/469]\tLoss_D: 805.4899\tLoss_G: 910.8622\tD(x): 716.7334\tD(G(z)): 929.4385 / -910.8622\n",
            "[1/20][50/469]\tLoss_D: -699.2546\tLoss_G: -3376.0303\tD(x): 6313.3203\tD(G(z)): 2725.9434 / 3376.0303\n",
            "[1/20][100/469]\tLoss_D: -9514.3164\tLoss_G: 3784.4912\tD(x): 7212.5127\tD(G(z)): -3629.1321 / -3784.4912\n",
            "[1/20][150/469]\tLoss_D: -4773.0005\tLoss_G: 23317.5352\tD(x): -13567.9453\tD(G(z)): -23199.5156 / -23317.5352\n",
            "[1/20][200/469]\tLoss_D: -810.5724\tLoss_G: -9990.8750\tD(x): 11555.9502\tD(G(z)): 9710.0957 / 9990.8750\n",
            "[1/20][250/469]\tLoss_D: 290.8184\tLoss_G: 254.5823\tD(x): 393.3748\tD(G(z)): 157.8267 / -254.5823\n",
            "[1/20][300/469]\tLoss_D: -1327.1510\tLoss_G: -1375.7579\tD(x): 3204.6602\tD(G(z)): 1485.4504 / 1375.7579\n",
            "[1/20][350/469]\tLoss_D: -257.0333\tLoss_G: -1499.8889\tD(x): 1635.7595\tD(G(z)): 1210.3333 / 1499.8889\n",
            "[1/20][400/469]\tLoss_D: -865.6259\tLoss_G: -3164.1724\tD(x): 4251.0430\tD(G(z)): 3018.8506 / 3164.1724\n",
            "[1/20][450/469]\tLoss_D: -432.4671\tLoss_G: -751.8279\tD(x): 1641.7351\tD(G(z)): 881.8116 / 751.8279\n",
            "[1/20][468/469]\tLoss_D: -1587.8833\tLoss_G: 1626.6497\tD(x): 825.4506\tD(G(z)): -1102.3164 / -1626.6497 t: 21.445\n",
            "[2/20][0/469]\tLoss_D: -1524.1521\tLoss_G: 1145.8342\tD(x): 891.7555\tD(G(z)): -1016.3673 / -1145.8342\n",
            "[2/20][50/469]\tLoss_D: -1598.9647\tLoss_G: -4228.6904\tD(x): 6835.9663\tD(G(z)): 4368.6885 / 4228.6904\n",
            "[2/20][100/469]\tLoss_D: -3542.5752\tLoss_G: 1111.0234\tD(x): 4544.8071\tD(G(z)): -792.3582 / -1111.0234\n",
            "[2/20][150/469]\tLoss_D: -4406.4854\tLoss_G: 3315.5754\tD(x): 5635.4028\tD(G(z)): -3151.1924 / -3315.5754\n",
            "[2/20][200/469]\tLoss_D: -4071.7510\tLoss_G: -3206.1687\tD(x): 11127.2510\tD(G(z)): 2680.7969 / 3206.1687\n",
            "[2/20][250/469]\tLoss_D: -4849.9600\tLoss_G: 1489.5040\tD(x): 9177.8369\tD(G(z)): -535.3580 / -1489.5040\n",
            "[2/20][300/469]\tLoss_D: -5428.7031\tLoss_G: -1053.9617\tD(x): 11315.1572\tD(G(z)): 1649.9961 / 1053.9617\n",
            "[2/20][350/469]\tLoss_D: -5518.2798\tLoss_G: 4370.8359\tD(x): 6956.8032\tD(G(z)): -3918.0583 / -4370.8359\n",
            "[2/20][400/469]\tLoss_D: -4573.5542\tLoss_G: 3620.1289\tD(x): 5637.2998\tD(G(z)): -4267.2676 / -3620.1289\n",
            "[2/20][450/469]\tLoss_D: -3632.6567\tLoss_G: -2608.6614\tD(x): 9608.8359\tD(G(z)): 2677.2832 / 2608.6614\n",
            "[2/20][468/469]\tLoss_D: -4245.6328\tLoss_G: 1414.2083\tD(x): 7903.5503\tD(G(z)): -131.3015 / -1414.2083 t: 21.221\n",
            "[3/20][0/469]\tLoss_D: -5895.0010\tLoss_G: 1047.3970\tD(x): 8484.4326\tD(G(z)): -1448.6934 / -1047.3970\n",
            "[3/20][50/469]\tLoss_D: -2925.1484\tLoss_G: -2449.4285\tD(x): 9020.0869\tD(G(z)): 2245.6362 / 2449.4285\n",
            "[3/20][100/469]\tLoss_D: -3480.6738\tLoss_G: -1254.5416\tD(x): 7296.8389\tD(G(z)): 1164.4082 / 1254.5416\n",
            "[3/20][150/469]\tLoss_D: -5889.3521\tLoss_G: 4895.7217\tD(x): 4642.8789\tD(G(z)): -5480.1553 / -4895.7217\n",
            "[3/20][200/469]\tLoss_D: -3198.2776\tLoss_G: 399.0207\tD(x): 5658.3496\tD(G(z)): -857.4596 / -399.0207\n",
            "[3/20][250/469]\tLoss_D: -4034.3584\tLoss_G: 4358.5283\tD(x): 4818.1045\tD(G(z)): -3185.9739 / -4358.5283\n",
            "[3/20][300/469]\tLoss_D: -1246.3533\tLoss_G: -1184.3220\tD(x): 5041.7949\tD(G(z)): 1829.3390 / 1184.3220\n",
            "[3/20][350/469]\tLoss_D: -2454.6770\tLoss_G: 5095.9390\tD(x): 329.1227\tD(G(z)): -5200.0024 / -5095.9390\n",
            "[3/20][400/469]\tLoss_D: -4016.8062\tLoss_G: 8097.4507\tD(x): 1050.7206\tD(G(z)): -6526.3042 / -8097.4507\n",
            "[3/20][450/469]\tLoss_D: -3753.3843\tLoss_G: 3679.1758\tD(x): 3324.1802\tD(G(z)): -3520.9365 / -3679.1758\n",
            "[3/20][468/469]\tLoss_D: -3236.5374\tLoss_G: -3335.1680\tD(x): 8097.8662\tD(G(z)): 2333.3372 / 3335.1680 t: 21.172\n",
            "[4/20][0/469]\tLoss_D: -3815.3335\tLoss_G: -3523.6462\tD(x): 9976.3711\tD(G(z)): 3371.0645 / 3523.6462\n",
            "[4/20][50/469]\tLoss_D: -3204.7468\tLoss_G: 1240.8938\tD(x): 4319.6675\tD(G(z)): -1464.8601 / -1240.8938\n",
            "[4/20][100/469]\tLoss_D: -3685.5374\tLoss_G: 4413.4727\tD(x): 1155.9473\tD(G(z)): -5223.7402 / -4413.4727\n",
            "[4/20][150/469]\tLoss_D: -4143.1909\tLoss_G: 1777.4617\tD(x): 5855.6362\tD(G(z)): -1686.4865 / -1777.4617\n",
            "[4/20][200/469]\tLoss_D: -4250.6035\tLoss_G: -1002.1837\tD(x): 9759.7607\tD(G(z)): 1709.1321 / 1002.1837\n",
            "[4/20][250/469]\tLoss_D: -3434.1748\tLoss_G: 767.4160\tD(x): 4975.7041\tD(G(z)): -1473.3833 / -767.4160\n",
            "[4/20][300/469]\tLoss_D: -3168.2449\tLoss_G: 2282.0544\tD(x): 4584.5322\tD(G(z)): -1513.8101 / -2282.0544\n",
            "[4/20][350/469]\tLoss_D: -2349.9524\tLoss_G: -2261.8604\tD(x): 6867.7520\tD(G(z)): 2319.4480 / 2261.8604\n",
            "[4/20][400/469]\tLoss_D: -2294.6997\tLoss_G: 2773.7180\tD(x): 2512.9946\tD(G(z)): -2170.3330 / -2773.7180\n",
            "[4/20][450/469]\tLoss_D: -6251.8003\tLoss_G: 2262.4531\tD(x): 7423.2656\tD(G(z)): -3226.5615 / -2262.4531\n",
            "[4/20][468/469]\tLoss_D: -5194.2056\tLoss_G: 3613.8406\tD(x): 5719.4468\tD(G(z)): -3983.6611 / -3613.8406 t: 21.067\n",
            "[5/20][0/469]\tLoss_D: -4409.3726\tLoss_G: 2449.1843\tD(x): 5502.6953\tD(G(z)): -2955.5610 / -2449.1843\n",
            "[5/20][50/469]\tLoss_D: -3923.8491\tLoss_G: -987.9613\tD(x): 7080.9893\tD(G(z)): 324.3338 / 987.9613\n",
            "[5/20][100/469]\tLoss_D: -5079.7246\tLoss_G: 2063.6260\tD(x): 6998.8809\tD(G(z)): -2011.8069 / -2063.6260\n",
            "[5/20][150/469]\tLoss_D: -3485.4587\tLoss_G: 5000.4365\tD(x): 2175.5825\tD(G(z)): -5231.2129 / -5000.4365\n",
            "[5/20][200/469]\tLoss_D: -3574.9568\tLoss_G: 3412.1162\tD(x): 2338.5762\tD(G(z)): -4066.6050 / -3412.1162\n"
          ]
        }
      ],
      "source": [
        "loss_name = 'wass'\n",
        "\n",
        "shuffle = True\n",
        "num_epochs = 20\n",
        "plot = True\n",
        "save_stats = True\n",
        "create_dir = True\n",
        "save_epochs = True\n",
        "momentumD, momentumG = 0.0, 0.0\n",
        "optimizer_name = 'adam'\n",
        "\n",
        "iter_per_epoch_dis, iter_per_epoch_gen, grad_penalty_coef = set_loss_params(\n",
        "    loss_name)\n",
        "\n",
        "stats, dataloader, netG, netD = run_experiment(ngpu, device, dataset, workers, batch_size,\n",
        "                                               shuffle, num_epochs, plot, lrD, lrG, beta1, nc, nz, loss_name, '', save_stats, create_dir,\n",
        "                                               iter_per_epoch_dis, iter_per_epoch_gen, grad_penalty_coef,\n",
        "                                               save_epochs, save_models, momentumD, momentumG, optimizer_name, PATH, count_params=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhfcOvw-GTCX"
      },
      "outputs": [],
      "source": [
        "img_list = stats['img_list']\n",
        "G_losses = stats['G_losses']\n",
        "D_losses = stats['D_losses']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-URPzv_TEhN7"
      },
      "source": [
        "# Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_repo_paths(PATH)"
      ],
      "metadata": {
        "id": "8WQCJUxd1BP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQ9voI50JsfC"
      },
      "outputs": [],
      "source": [
        "save_path = PATH + 'img/real_vs_fake'\n",
        "plot_loss(G_losses, D_losses, save_path, save=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrhkQ1fwJrJa"
      },
      "outputs": [],
      "source": [
        "plot_realvsfake(dataloader, device, img_list, PATH + 'img/loss', save=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA4p6YNOEhN7"
      },
      "source": [
        "## G’s progression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI3SO9R1EhN7"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpIukUkR5ny_"
      },
      "source": [
        "# Hyperparameter optimisation (gridsearch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTdcMZ4AtiVw"
      },
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "dataroot = PATH + \"data/\"\n",
        "\n",
        "# Dataset name\n",
        "dataset_name = 'mnist'  # 'cifar10' or 'mnist'\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this size using a transformer\n",
        "image_size = 28  # 28 for mnist, 64 for others\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 128\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A9CMfg2ykYB"
      },
      "outputs": [],
      "source": [
        "create_repo_paths(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRqoAVcKtC05"
      },
      "outputs": [],
      "source": [
        "dataset, nc = get_dataset(dataset_name, image_size, dataroot)\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEmdQBI_LFcW"
      },
      "outputs": [],
      "source": [
        "grid_search(ngpu, device, dataset, workers,\n",
        "            experiment_prefix='',           # add an extra word at the begining to the save path of the models and stats\n",
        "            batch_size_list=[128],\n",
        "            shuffle_list=[True],\n",
        "            num_epochs_list=[300],\n",
        "            loss_name_list=['wass'],        # wass, hinge\n",
        "            optimizer_name_list=['adam', 'sgd', 'rmsprop'],   # 'adam' 'sgd' 'rmsprop'\n",
        "            beta1_list=[0.9],               # 0.9 == default # Beta1 hyperparam for Adam optimizers\n",
        "            lr_list=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7],\n",
        "            momentums_list=[(0, 0)],        # [(momentumD, momentumG)]\n",
        "            plot=False,\n",
        "            save_stats=True,                # save the stats to disk\n",
        "            create_dir=True,                # create the directories to save files\n",
        "            save_epochs=10,                 # save the model every save_epochs epochs\n",
        "            save_models=True,               # save the models to disk\n",
        "            manualSeed=123,                 # keep at 123\n",
        "            nc=nc, nz=nz,\n",
        "            PATH=PATH\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I0l7YpXz09P4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-URPzv_TEhN7"
      ],
      "name": "gan.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "6a6457a5aade1d7f0f784b93b9d1e5b6320a7fcf78907f3f0ade3d2c3999d686"
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 ('optmlgan')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "6a6457a5aade1d7f0f784b93b9d1e5b6320a7fcf78907f3f0ade3d2c3999d686"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}