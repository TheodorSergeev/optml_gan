{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheodorSergeev/optml_gan/blob/main/dcgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fe1zK4TEn2P"
      },
      "source": [
        "Adapted from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElE3epO2FCLq"
      },
      "source": [
        "# Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg1MBmvsdWEd",
        "outputId": "2c66a80f-d454-420c-e9ab-24b361acc456"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:  \n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # packages to generate requirement.txt\n",
        "    %pip install nbconvert\n",
        "    %pip install pipreqs\n",
        "    # for Frechet inception distance\n",
        "    %pip install pytorch-fid\n",
        "\n",
        "    %cd drive/My Drive/optml_gan2\n",
        "    PATH = './' \n",
        "else:\n",
        "    PATH = './' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M50Mkga4EhNy"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from datetime import datetime\n",
        "import json\n",
        "import pickle\n",
        "from scipy import linalg\n",
        "from torch.nn.functional import adaptive_avg_pool2d\n",
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except ImportError:\n",
        "    # If tqdm is not available, provide a mock version of it\n",
        "    def tqdm(x):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQY6pqVIgdUH"
      },
      "source": [
        "# Generate Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YaRkKzQNgdUH"
      },
      "outputs": [],
      "source": [
        "# # converts notebook to .py file for pipreqs\n",
        "# !jupyter nbconvert --output-dir=\"./\" --to script dcgan.ipynb \n",
        "\n",
        "# # creates the requirement.txt file\n",
        "# !pipreqs --force\n",
        "# os.remove('./dcgan.py')  # deletes the .py file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqmZqleaEhN0"
      },
      "source": [
        "# Source code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDrLP1SExqZT"
      },
      "source": [
        "## Data handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NP4dzAueOkhe"
      },
      "outputs": [],
      "source": [
        "# there are problems with downloading CelebA\n",
        "# see https://stackoverflow.com/questions/65528568/how-do-i-load-the-celeba-dataset-on-google-colab-using-torch-vision-without-ru\n",
        "\n",
        "def get_dataset(name, image_size, dataroot):\n",
        "    # torchvision dataset\n",
        "    dataset = None\n",
        "\n",
        "    # number of channels in the training images (3 for color, 1 for grayscale)\n",
        "    nc = None\n",
        "\n",
        "    if name == 'cifar10':\n",
        "        nc = 3\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.CenterCrop(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5) # todo: Why do we use these means and stds ? \n",
        "        )])\n",
        "\n",
        "        dataset = torchvision.datasets.CIFAR10(dataroot, download=True, \n",
        "                                            train=True,  transform=transform)\n",
        "    elif name == 'mnist':\n",
        "        nc = 1\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.CenterCrop(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5), (0.5)) # todo: Why do we use these means and stds and not the mean and std of the dataset?\n",
        "        ])\n",
        "\n",
        "        dataset = torchvision.datasets.MNIST(dataroot, download=True, \n",
        "                                            train=True,  transform=transform)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown dataset name\")\n",
        "    \n",
        "    return dataset, nc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J0M-_II2wgTC"
      },
      "outputs": [],
      "source": [
        "def plot_img(dataloader, dataset_name):\n",
        "    # Plot some training images\n",
        "    real_batch = next(iter(dataloader))\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Training Images\")\n",
        "    plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "    plt.savefig(PATH + 'img/training_images_' + dataset_name, format=\"png\", dpi=400)\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_qwUuFhj_k-"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i_55CgnekALb"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    # from https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325/9\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def create_repo_paths(PATH):\n",
        "    data_path = PATH + '/data'\n",
        "    generated_data_path = PATH + '/generated_data'\n",
        "    img_path = PATH + '/img'\n",
        "    src_path = PATH + '/src'\n",
        "    os.makedirs(data_path, exist_ok=True)\n",
        "    os.makedirs(generated_data_path, exist_ok=True)\n",
        "    os.makedirs(img_path, exist_ok=True)\n",
        "    os.makedirs(src_path, exist_ok=True)\n",
        "    return\n",
        "# Paths to load and save the models\n",
        "\n",
        "\n",
        "def generate_paths(PATH, extra_word, loss_name, lrD, lrG, beta1, iter_dis, iter_gen, grad_penalty_coef, create_dir):\n",
        "\n",
        "    param_str = loss_name + 'Loss_' + 'lrd' + \\\n",
        "        str(lrD) + '_lrg' + str(lrG) + '_b1' + 'b' + str(beta1)\n",
        "    param_str = param_str + '_itd' + \\\n",
        "        str(iter_dis) + '_itg' + str(iter_gen) + \\\n",
        "        '_gpv' + str(grad_penalty_coef) + '_'\n",
        "\n",
        "    # + str(datetime.date(datetime.now())).replace('-', '_') + \"_\"\n",
        "    experiment_path = PATH + \"generated_data/\" + extra_word + param_str\n",
        "\n",
        "    models_path = experiment_path + '/models/'\n",
        "\n",
        "    stats_path = experiment_path + '/stat.pickle'\n",
        "\n",
        "    if create_dir:\n",
        "        os.makedirs(models_path, exist_ok=True)\n",
        "        os.makedirs(experiment_path, exist_ok=True)\n",
        "\n",
        "    return experiment_path, stats_path, models_path\n",
        "\n",
        "\n",
        "def model_paths(experiment_path, epoch, models_path):\n",
        "\n",
        "    model_name_G = 'model_G_' + str(epoch)\n",
        "    save_path_G = models_path + model_name_G\n",
        "\n",
        "    model_name_D = 'model_D_'+str(epoch)\n",
        "    save_path_D = models_path + model_name_D\n",
        "\n",
        "    return save_path_G, save_path_D\n",
        "\n",
        "\n",
        "def set_seeds(manualSeed=123):\n",
        "    # Set random seed for reproducibility\n",
        "\n",
        "    # manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "    print(\"Random Seed: \", manualSeed)\n",
        "    random.seed(manualSeed)\n",
        "    torch.manual_seed(manualSeed)\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UNmOJSYEhN1"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bjjgdB2YEhN2"
      },
      "outputs": [],
      "source": [
        "# Custom weights initialisation called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Sa42nmjtEhN4"
      },
      "outputs": [],
      "source": [
        "def init_net(model, device):\n",
        "    # Create the generator\n",
        "    net = model.to(device)\n",
        "\n",
        "    # Handle multi-gpu if desired\n",
        "    if (device.type == 'cuda') and (ngpu > 1):\n",
        "        net = nn.DataParallel(net, list(range(ngpu)))\n",
        "\n",
        "    # Apply the weights_init function to randomly initialise all weights\n",
        "    #  to mean=0, stdev=0.02.\n",
        "    # net.apply(weights_init)\n",
        "\n",
        "    # Print the model\n",
        "    print(net)\n",
        "    return net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAhsK2LyUnb_"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YUeIrmkvUqV0"
      },
      "outputs": [],
      "source": [
        "# stability constant\n",
        "EPS = 1e-15\n",
        "\n",
        "\n",
        "# KL-divergence\n",
        "def loss_gen_kl(dis_output, eps=EPS):\n",
        "    return - torch.log(dis_output + eps).mean()\n",
        "\n",
        "\n",
        "def loss_dis_kl(dis_output_real, dis_output_fake, eps=EPS):\n",
        "    return - (torch.log(dis_output_real + eps)).mean() - (torch.log(1. - dis_output_fake + eps)).mean()\n",
        "\n",
        "\n",
        "# Wasserstein distance\n",
        "# Requires special output of the network + weight clipping / grad penalty\n",
        "def loss_gen_wasser(dis_output, eps=EPS):\n",
        "    return - dis_output.mean()\n",
        "\n",
        "\n",
        "def loss_dis_wasser(dis_output_real, dis_output_fake, eps=EPS):\n",
        "    return - (dis_output_real.mean() - dis_output_fake.mean())\n",
        "\n",
        "\n",
        "# Hinge loss\n",
        "def loss_gen_hinge(dis_output, eps=EPS):\n",
        "    return - dis_output.mean()\n",
        "\n",
        "\n",
        "def loss_dis_hinge(dis_output_real, dis_output_fake, eps=EPS):\n",
        "    return torch.nn.ReLU()(1.0 - dis_output_real).mean() + torch.nn.ReLU()(1.0 + dis_output_fake).mean()\n",
        "\n",
        "\n",
        "loss_dict = {\n",
        "    \"kl\": (loss_dis_kl, loss_gen_kl),\n",
        "    \"wass\": (loss_dis_wasser, loss_gen_wasser),\n",
        "    \"hinge\": (loss_dis_hinge, loss_gen_hinge)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwd6NVO7zoze"
      },
      "source": [
        "## FID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJpwdqHN1lN-"
      },
      "source": [
        "https://www.kaggle.com/code/ibtesama/gan-in-pytorch-with-fid/notebook  \n",
        "https://github.com/mseitzer/pytorch-fid   \n",
        "https://github.com/mseitzer/pytorch-fid/blob/master/src/pytorch_fid/fid_score.py\n",
        "Currently uses the Kaggle stuff since calculating FID on the repo is run from the command line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YxtQ5pk4z_0M"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class InceptionV3(nn.Module):\n",
        "    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n",
        "\n",
        "    # Index of default block of inception to return,\n",
        "    # corresponds to output of final average pooling\n",
        "    DEFAULT_BLOCK_INDEX = 3\n",
        "\n",
        "    # Maps feature dimensionality to their output blocks indices\n",
        "    BLOCK_INDEX_BY_DIM = {\n",
        "        64: 0,   # First max pooling features\n",
        "        192: 1,  # Second max pooling featurs\n",
        "        768: 2,  # Pre-aux classifier features\n",
        "        2048: 3  # Final average pooling features\n",
        "    }\n",
        "\n",
        "    def __init__(self,\n",
        "                 output_blocks=[DEFAULT_BLOCK_INDEX],\n",
        "                 resize_input=True,\n",
        "                 normalize_input=True,\n",
        "                 requires_grad=False):\n",
        "\n",
        "        super(InceptionV3, self).__init__()\n",
        "\n",
        "        self.resize_input = resize_input\n",
        "        self.normalize_input = normalize_input\n",
        "        self.output_blocks = sorted(output_blocks)\n",
        "        self.last_needed_block = max(output_blocks)\n",
        "\n",
        "        assert self.last_needed_block <= 3, \\\n",
        "            'Last possible output block index is 3'\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "\n",
        "        inception = models.inception_v3(pretrained=True)\n",
        "\n",
        "        # Block 0: input to maxpool1\n",
        "        block0 = [\n",
        "            inception.Conv2d_1a_3x3,\n",
        "            inception.Conv2d_2a_3x3,\n",
        "            inception.Conv2d_2b_3x3,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        ]\n",
        "        self.blocks.append(nn.Sequential(*block0))\n",
        "\n",
        "        # Block 1: maxpool1 to maxpool2\n",
        "        if self.last_needed_block >= 1:\n",
        "            block1 = [\n",
        "                inception.Conv2d_3b_1x1,\n",
        "                inception.Conv2d_4a_3x3,\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block1))\n",
        "\n",
        "        # Block 2: maxpool2 to aux classifier\n",
        "        if self.last_needed_block >= 2:\n",
        "            block2 = [\n",
        "                inception.Mixed_5b,\n",
        "                inception.Mixed_5c,\n",
        "                inception.Mixed_5d,\n",
        "                inception.Mixed_6a,\n",
        "                inception.Mixed_6b,\n",
        "                inception.Mixed_6c,\n",
        "                inception.Mixed_6d,\n",
        "                inception.Mixed_6e,\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block2))\n",
        "\n",
        "        # Block 3: aux classifier to final avgpool\n",
        "        if self.last_needed_block >= 3:\n",
        "            block3 = [\n",
        "                inception.Mixed_7a,\n",
        "                inception.Mixed_7b,\n",
        "                inception.Mixed_7c,\n",
        "                nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block3))\n",
        "\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = requires_grad\n",
        "\n",
        "    def forward(self, inp):\n",
        "        \"\"\"Get Inception feature maps\n",
        "        Parameters\n",
        "        ----------\n",
        "        inp : torch.autograd.Variable\n",
        "            Input tensor of shape Bx3xHxW. Values are expected to be in\n",
        "            range (0, 1)\n",
        "        Returns\n",
        "        -------\n",
        "        List of torch.autograd.Variable, corresponding to the selected output\n",
        "        block, sorted ascending by index\n",
        "        \"\"\"\n",
        "        outp = []\n",
        "        x = inp\n",
        "\n",
        "        if self.resize_input:\n",
        "            x = F.interpolate(x,\n",
        "                              size=(299, 299),\n",
        "                              mode='bilinear',\n",
        "                              align_corners=False)\n",
        "\n",
        "        if self.normalize_input:\n",
        "            x = 2 * x - 1  # Scale from range (0, 1) to range (-1, 1)\n",
        "\n",
        "        for idx, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "            if idx in self.output_blocks:\n",
        "                outp.append(x)\n",
        "\n",
        "            if idx == self.last_needed_block:\n",
        "                break\n",
        "\n",
        "        return outp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_activations(isreal, dataloader, num_samples, model, dims=2048, device='cpu'):\n",
        "    \"\"\"Calculates the activations of the pool_3 layer for all images.\n",
        "    Params:\n",
        "    -- files       : List of image files paths\n",
        "    -- model       : Instance of inception model\n",
        "    -- batch_size  : Batch size of images for the model to process at once.\n",
        "                     Make sure that the number of samples is a multiple of\n",
        "                     the batch size, otherwise some samples are ignored. This\n",
        "                     behavior is retained to match the original FID score\n",
        "                     implementation.\n",
        "    -- dims        : Dimensionality of features returned by Inception\n",
        "    -- device      : Device to run calculations\n",
        "    -- num_workers : Number of parallel dataloader workers\n",
        "    Returns:\n",
        "    -- A numpy array of dimension (num images, dims) that contains the\n",
        "       activations of the given tensor when feeding inception with the\n",
        "       query tensor.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    pred_arr = np.empty((num_samples, dims))\n",
        "\n",
        "    start_idx = 0\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        # if isreal:\n",
        "        # batch = batch\n",
        "        batch = batch[0].to(device)\n",
        "        batch = batch.repeat_interleave(repeats=3, dim=1) # broadcast the 1 grayscale channel to 3 channels\n",
        "        with torch.no_grad():\n",
        "            pred = model(batch)[0]\n",
        "\n",
        "        # If model output is not scalar, apply global spatial average pooling.\n",
        "        # This happens if you choose a dimensionality not equal 2048.\n",
        "        if pred.size(2) != 1 or pred.size(3) != 1:\n",
        "            pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
        "\n",
        "        pred = pred.squeeze(3).squeeze(2).cpu().numpy()\n",
        "\n",
        "        pred_arr[start_idx:start_idx + pred.shape[0]] = pred\n",
        "        \n",
        "        start_idx = start_idx + pred.shape[0]\n",
        "\n",
        "    return pred_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_activation_statistics(isreal, dataloader, num_samples, model, dims=2048,\n",
        "                                    device='cpu'):\n",
        "    \"\"\"Calculation of the statistics used by the FID.\n",
        "    Params:\n",
        "\n",
        "    -- model       : Instance of inception model\n",
        "    -- batch_size  : The images numpy array is split into batches with\n",
        "                     batch size batch_size. A reasonable batch size\n",
        "                     depends on the hardware.\n",
        "    -- dims        : Dimensionality of features returned by Inception\n",
        "    -- device      : Device to run calculations\n",
        "    -- num_workers : Number of parallel dataloader workers\n",
        "    Returns:\n",
        "    -- mu    : The mean over samples of the activations of the pool_3 layer of\n",
        "               the inception model.\n",
        "    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n",
        "               the inception model.\n",
        "    \"\"\"\n",
        "\n",
        "    act = get_activations(isreal,dataloader, num_samples, model, dims, device)\n",
        "    mu = np.mean(act, axis=0)\n",
        "    sigma = np.cov(act, rowvar=False)\n",
        "    return mu, sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "heCyV4qHzu3D"
      },
      "outputs": [],
      "source": [
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
        "    \"\"\"Numpy implementation of the Frechet Distance.\n",
        "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
        "    and X_2 ~ N(mu_2, C_2) is\n",
        "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
        "    \"\"\"\n",
        "\n",
        "    mu1 = np.atleast_1d(mu1)\n",
        "    mu2 = np.atleast_1d(mu2)\n",
        "\n",
        "    sigma1 = np.atleast_2d(sigma1)\n",
        "    sigma2 = np.atleast_2d(sigma2)\n",
        "\n",
        "    assert mu1.shape == mu2.shape, \\\n",
        "        'Training and test mean vectors have different lengths'\n",
        "    assert sigma1.shape == sigma2.shape, \\\n",
        "        'Training and test covariances have different dimensions'\n",
        "\n",
        "    diff = mu1 - mu2\n",
        "\n",
        "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    if not np.isfinite(covmean).all():\n",
        "        msg = ('fid calculation produces singular product; '\n",
        "               'adding %s to diagonal of cov estimates') % eps\n",
        "        print(msg)\n",
        "        offset = np.eye(sigma1.shape[0]) * eps\n",
        "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
        "\n",
        "    if np.iscomplexobj(covmean):\n",
        "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "            m = np.max(np.abs(covmean.imag))\n",
        "            raise ValueError('Imaginary component {}'.format(m))\n",
        "        covmean = covmean.real\n",
        "\n",
        "    tr_covmean = np.trace(covmean)\n",
        "\n",
        "    return (diff.dot(diff) + np.trace(sigma1) +\n",
        "            np.trace(sigma2) - 2 * tr_covmean)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uBzRjX6Bzu06"
      },
      "outputs": [],
      "source": [
        "def calculate_frechet(device, real_dataloader, fake_dataloader, inception_model) :\n",
        "    mu_1, std_1 = calculate_activation_statistics(True, real_dataloader, num_samples,\n",
        "         inception_model, device=device)\n",
        "    mu_2, std_2 = calculate_activation_statistics(False, fake_dataloader, num_samples,\n",
        "         inception_model, device=device)\n",
        "\n",
        "    \"\"\"get Frechet distance\"\"\"\n",
        "    fid_value = calculate_frechet_distance(mu_1, std_1, mu_2, std_2)\n",
        "    return fid_value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfjSFPjEyGg_"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "V0i7nSDwyFy9"
      },
      "outputs": [],
      "source": [
        "def init_optimizers(optimizer_name, netD, netG, lrD, lrG, beta1, nz, device,\n",
        "                    momentumD, momentumG):\n",
        "\n",
        "    # Create batch of latent vectors that we will use to visualize\n",
        "    #  the progression of the generator\n",
        "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "    # Establish convention for real and fake labels during training\n",
        "    real_label = 1.\n",
        "    fake_label = 0.\n",
        "\n",
        "    if optimizer_name == 'adam':\n",
        "        # Setup Adam optimisers for both G and D\n",
        "        optimizerD = optim.Adam(\n",
        "            netD.parameters(), lr=lrD, betas=(beta1, 0.999))\n",
        "        optimizerG = optim.Adam(\n",
        "            netG.parameters(), lr=lrG, betas=(beta1, 0.999))\n",
        "    if optimizer_name == 'sgd':\n",
        "        optimizerD = optim.SGD(netD.parameters(), lr=lrD,\n",
        "                               momentum=momentumD, dampening=0, weight_decay=0)\n",
        "        optimizerG = optim.SGD(netG.parameters(), lr=lrG,\n",
        "                               momentum=momentumG, dampening=0, weight_decay=0)\n",
        "    if optimizer_name == 'rmsprop':\n",
        "        optimizerD = optim.RMSprop(netD.parameters(\n",
        "        ), lr=lrD, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
        "        optimizerG = optim.RMSprop(netG.parameters(\n",
        "        ), lr=lrG, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
        "\n",
        "    return fixed_noise, real_label, fake_label, optimizerD, optimizerG\n",
        "\n",
        "\n",
        "def init_losses(loss_type):\n",
        "    if loss_type not in loss_dict.keys():\n",
        "        raise Exception(\"Unknown loss type\")\n",
        "\n",
        "    return loss_dict[loss_type]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2DyNJjV7IQif"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "def gradient_penalty(device, discriminator, data_gen, data_real, lambda_reg=0.1):\n",
        "    alpha = torch.rand(data_real.shape[0], 1).to(device)\n",
        "    dims_to_add = len(data_real.size()) - 2\n",
        "    for i in range(dims_to_add):\n",
        "        alpha = alpha.unsqueeze(-1)\n",
        "\n",
        "    interpolates = (alpha * data_real + ((1. - alpha) * data_gen)).to(device)\n",
        "\n",
        "    interpolates = Variable(interpolates, requires_grad=True)\n",
        "\n",
        "    disc_interpolates = discriminator(interpolates)\n",
        "    grad_outputs = torch.ones(disc_interpolates.size()).to(device)\n",
        "\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=disc_interpolates, inputs=interpolates, grad_outputs=grad_outputs,\n",
        "        create_graph=True, retain_graph=True, only_inputs=True\n",
        "    )[0]\n",
        "\n",
        "    grad_penalty_coef = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lambda_reg\n",
        "\n",
        "    return grad_penalty_coef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ktvJ-tAULJuc"
      },
      "outputs": [],
      "source": [
        "def discriminator_step(optimizerD, f_loss_dis, netD, netG, data, device, real_label, fake_label, gp_coef):\n",
        "    netD.zero_grad()\n",
        "\n",
        "    real_cpu = data[0].to(device)\n",
        "    b_size = real_cpu.size(0)\n",
        "    label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "    output_real = netD(real_cpu).view(-1)\n",
        "\n",
        "    noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "    fake = netG(noise)\n",
        "    label.fill_(fake_label)\n",
        "    output_fake = netD(fake.detach()).view(-1)\n",
        "\n",
        "    errD = f_loss_dis(output_real, output_fake)\n",
        "\n",
        "    if gp_coef != 0.0:\n",
        "        errD += gp_coef * gradient_penalty(device, netD, fake, real_cpu)\n",
        "\n",
        "    errD.backward()\n",
        "    optimizerD.step()\n",
        "\n",
        "    D_x = output_real.mean().item()\n",
        "    D_G_z1 = output_fake.mean().item()\n",
        "\n",
        "    return D_x, D_G_z1, errD, label, fake, real_cpu\n",
        "\n",
        "\n",
        "def generator_step(optimizerG, f_loss_gen, netD, netG, label, fake, real_label):\n",
        "    netG.zero_grad()\n",
        "    output = netD(fake).view(-1)\n",
        "    \n",
        "    errG = f_loss_gen(output)\n",
        "    errG.backward()\n",
        "    \n",
        "    D_G_z2 = output.mean().item()\n",
        "\n",
        "    optimizerG.step()\n",
        "    return D_G_z2, errG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ezKphnm8gdUP"
      },
      "outputs": [],
      "source": [
        "class Training:\n",
        "    def __init__(self, loss_name, netD, netG, device, real_label, fake_label, dataloader, num_epochs,\n",
        "                 fixed_noise, lrD, lrG, beta1, experiment_prefix, save_models, \n",
        "                 PATH, save_stats, create_dir, iter_per_epoch_dis, iter_per_epoch_gen, grad_penalty_coef,\n",
        "                 optimizerD, optimizerG,\n",
        "                 save_epochs=10):\n",
        "        self.optimizerD, self.optimizerG = optimizerD, optimizerG\n",
        "\n",
        "        self.loss_name = loss_name\n",
        "        self.netD, self.netG = netD, netG\n",
        "        self.device = device\n",
        "        self.real_label, self.fake_label = real_label, fake_label\n",
        "        self.dataloader = dataloader\n",
        "        self.num_epochs = num_epochs\n",
        "        self.fixed_noise = fixed_noise\n",
        "        self.iter_per_epoch_dis, self.iter_per_epoch_gen = iter_per_epoch_dis, iter_per_epoch_gen\n",
        "        self.grad_penalty_coef = grad_penalty_coef\n",
        "\n",
        "        self.save_models = save_models\n",
        "        self.PATH = PATH\n",
        "        self.experiment_prefix = experiment_prefix\n",
        "        self.loss_name = loss_name\n",
        "        self.lrD = lrD\n",
        "        self.lrG = lrG\n",
        "        self.beta1 = beta1\n",
        "        self.create_dir = create_dir\n",
        "        self.save_stats = save_stats\n",
        "        self.save_epochs = save_epochs\n",
        "        self.experiment_path, self.stats_path, self.models_path = generate_paths(self.PATH, self.experiment_prefix, \n",
        "                                                          self.loss_name, self.lrD, self.lrG, \n",
        "                                                          self.beta1, self.iter_per_epoch_dis, self.iter_per_epoch_gen, \n",
        "                                                          self.grad_penalty_coef, self.create_dir)\n",
        "        # self.inception_model = inception_model\n",
        "\n",
        "    def _output_training_stats(self, epoch, i, size, errD, errG, D_x, D_G_z1, D_G_z2, t0):\n",
        "        if i == size:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f t: %2.3f'\n",
        "                % (epoch, self.num_epochs, i, len(self.dataloader),\n",
        "                    errD, errG, D_x, D_G_z1, D_G_z2, time.time()-t0))\n",
        "        elif i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                % (epoch, self.num_epochs, i, len(self.dataloader),\n",
        "                    errD, errG, D_x, D_G_z1, D_G_z2))\n",
        "    \n",
        "    def _save_gen_output(self, iters, epoch, i):\n",
        "        if iters % 500 == 0 or (epoch == self.num_epochs-1) and (i == len(self.dataloader)-1):\n",
        "            with torch.no_grad():\n",
        "                fake = self.netG(self.fixed_noise).detach().cpu()\n",
        "            self.img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "            # maybe remove this if we have memory problems\n",
        "            self.img_list_nogrid.append(fake)\n",
        "\n",
        "    def train(self):\n",
        "        f_loss_dis, f_loss_gen = init_losses(self.loss_name)\n",
        "\n",
        "        G_losses, D_losses = [], []\n",
        "        self.img_list = []\n",
        "        self.img_list_nogrid = []\n",
        "\n",
        "        iters = 0\n",
        "\n",
        "        print(\"Starting Training Loop...\")\n",
        "\n",
        "        D_x, D_G_z1, errD, label, fake = None, None, None, None, None\n",
        "        D_G_z2, errG = None, None\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            t0 = time.time()\n",
        "\n",
        "            for i, data in enumerate(self.dataloader, 0):\n",
        "                for _ in range(self.iter_per_epoch_dis):\n",
        "                    D_x, D_G_z1, errD, label, fake, real_cpu = discriminator_step(self.optimizerD,\n",
        "                        f_loss_dis, self.netD, self.netG, data, self.device, \n",
        "                        self.real_label, self.fake_label, self.grad_penalty_coef\n",
        "                    )\n",
        "\n",
        "                for _ in range(self.iter_per_epoch_gen):\n",
        "                    D_G_z2, errG = generator_step(self.optimizerG,\n",
        "                        f_loss_gen, self.netD, self.netG, label, fake, self.real_label\n",
        "                    )\n",
        "                \n",
        "                # Save Losses for plotting later\n",
        "                G_losses.append(errG.item())\n",
        "                D_losses.append(errD.item())\n",
        "\n",
        "                size = len(self.dataloader) - 1\n",
        "                self._output_training_stats(epoch, i, size, errD.item(), errG.item(), D_x, D_G_z1, D_G_z2, t0)\n",
        "                \n",
        "                # Check how the generator is doing by saving G's output on fixed_noise\n",
        "                self._save_gen_output(iters, epoch, i)\n",
        "                \n",
        "                iters += 1\n",
        "\n",
        "            # save the model every self.save_epochs epochs\n",
        "            if self.save_models and (epoch % self.save_epochs == self.save_epochs - 1):\n",
        "                self.save_path_G, self.save_path_D = model_paths(self.experiment_path, epoch, self.models_path)\n",
        "                save_models(self.netG, self.netD, self.save_path_G, self.save_path_D)\n",
        "\n",
        "        stats = {\n",
        "            'img_list' : self.img_list,\n",
        "            'img_list_nogrid' : self.img_list_nogrid,\n",
        "            'G_losses' : G_losses,\n",
        "            'D_losses' : D_losses  \n",
        "        }\n",
        "        # save stats at the end of training\n",
        "        if self.save_stats:\n",
        "            pickle_save(stats, self.stats_path)\n",
        "\n",
        "        return stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76HIJHth6szw"
      },
      "source": [
        "## Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZDqpaE6i6uLu"
      },
      "outputs": [],
      "source": [
        "def plot_loss(G_losses, D_losses, save = False):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "    plt.plot(G_losses, label=\"G\")\n",
        "    plt.plot(D_losses, label=\"D\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    if save == True:\n",
        "      plt.savefig(PATH + 'img/loss', format=\"png\",dpi=400)\n",
        "\n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OMjT45Nw7BBf"
      },
      "outputs": [],
      "source": [
        "def plot_realvsfake(dataloader, device, img_list, save = False):\n",
        "    # Grab a batch of real images from the dataloader\n",
        "    real_batch = next(iter(dataloader))\n",
        "\n",
        "    # Plot the real images\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Real Images\")\n",
        "    plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "    # Plot the fake images from the last epoch\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Fake Images\")\n",
        "    plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "    if save == True:\n",
        "        plt.savefig(PATH + 'img/real_vs_fake', format=\"png\",dpi=400)\n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFOlQTaL7ibw"
      },
      "source": [
        "## Serialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "x9OTjxEH7rg6"
      },
      "outputs": [],
      "source": [
        "def save_models(netG ,netD, save_path_G, save_path_D):\n",
        "    torch.save(netG.state_dict(), save_path_G)\n",
        "    torch.save(netD.state_dict(), save_path_D)\n",
        "    print('GAN saved')\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TSCzFlDT7kE3"
      },
      "outputs": [],
      "source": [
        "def load_models(ngpu, Discriminator, Generator, save_path_G, save_path_D):\n",
        "  \n",
        "    netD = init_net(Discriminator(ngpu, nc, loss_name), device)\n",
        "    netD.load_state_dict(torch.load(save_path_D))\n",
        "    netD.eval()\n",
        "\n",
        "    netG = init_net(Generator(ngpu, nc, nz), device)\n",
        "    netG.load_state_dict(torch.load(save_path_G))\n",
        "    netG.eval()\n",
        "    \n",
        "    print('GAN loaded')\n",
        "    return netD, netG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ukW6LisRmoxO"
      },
      "outputs": [],
      "source": [
        "def save_dict(dict, dict_path):\n",
        "    with open(dict_path, 'w') as file:\n",
        "        file.write(json.dumps(dict))  \n",
        "    return\n",
        "\n",
        "def read_dict(dict_path):\n",
        "    with open(dict_path) as f:\n",
        "        data = f.read()\n",
        "    data = json.loads(data)\n",
        "    return data\n",
        "\n",
        "def pickle_save(something, path):\n",
        "    with open(path, 'wb') as handle:\n",
        "        pickle.dump(something, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def pickle_load (path):\n",
        "    with open(path, 'rb') as handle:\n",
        "        something = pickle.load(handle)\n",
        "    return something"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cjD_s6dFNzL"
      },
      "source": [
        "## Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxcNcsuwIgYu"
      },
      "source": [
        "https://keras.io/examples/generative/conditional_gan/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BJcokCcO5E0d"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu, nc, nz):\n",
        "        super(Generator, self).__init__()       \n",
        "        self.fc1 = nn.Linear(nz, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, nc * 28 * 28)\n",
        "        return    \n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x): \n",
        "        x = x.reshape([x.shape[0], -1])\n",
        "\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = torch.tanh(self.fc4(x))\n",
        "        x = x.reshape((-1, nc, 28, 28))\n",
        "        return x\n",
        "    \n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu, nc, loss):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "\n",
        "        if loss == \"kl\":\n",
        "            # for KL - discriminator is a classifier\n",
        "            self.act = torch.sigmoid\n",
        "        else:\n",
        "            # for Wasserstein and hinge - discriminator is a critic\n",
        "            self.act = lambda x: x\n",
        "\n",
        "        return    \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape([x.shape[0], -1])\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = self.act(self.fc4(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpIukUkR5ny_"
      },
      "source": [
        "# Hyperparameter optimisation (gridsearch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "N7dlYcZspm9i"
      },
      "outputs": [],
      "source": [
        "def set_loss_params(loss_name):\n",
        "    \n",
        "    iter_dis, iter_gen, grad_penalty_coef = 1, 1, 0.0\n",
        "\n",
        "    if loss_name == \"wass\":\n",
        "        iter_dis, grad_penalty_coef = 5, 10.0\n",
        "\n",
        "    return iter_dis, iter_gen, grad_penalty_coef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9Nwk5FBy5nbU"
      },
      "outputs": [],
      "source": [
        "def run_experiment(ngpu, device, dataset, workers,\n",
        "                   batch_size, shuffle, num_epochs, plot, lrD, lrG, beta1, nz, \n",
        "                   loss_name, experiment_prefix, save_stats, create_dir, \n",
        "                   iter_per_epoch_dis, iter_per_epoch_gen, grad_penalty_coef, \n",
        "                   save_epochs, save_models, momentumD, momentumG, optimizer_name): \n",
        "\n",
        "\n",
        "    netG = init_net(Generator(ngpu, nc, nz), device)\n",
        "    netD = init_net(Discriminator(ngpu, nc, loss_name), device)\n",
        "    \n",
        "    # Create the dataloader\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                            shuffle=True, num_workers=workers)\n",
        "     \n",
        "    fixed_noise, real_label, fake_label, optimizerD, optimizerG = init_optimizers(optimizer_name, netD, netG, lrD, lrG, beta1, nz, device, momentumD, momentumG)\n",
        "\n",
        "    experiment_prefix = experiment_prefix + optimizer_name +'_mG'+str(momentumD) +'_mD'+str(momentumG) + '_'\n",
        "\n",
        "    gan_training = Training(loss_name, netD, netG, device, real_label, fake_label, \n",
        "                            dataloader, num_epochs, fixed_noise, \n",
        "                            lrD, lrG, beta1, experiment_prefix, save_models, PATH, save_stats, create_dir,\n",
        "                            iter_per_epoch_dis, iter_per_epoch_gen, grad_penalty_coef, optimizerD, optimizerG, save_epochs=save_epochs)\n",
        "\n",
        "    stats = gan_training.train()\n",
        "    \n",
        "    if plot:\n",
        "        plot_loss(G_losses, D_losses, save = False)\n",
        "        plot_realvsfake(dataloader, device, img_list, save = False)\n",
        "    \n",
        "    return stats, dataloader, netG, netD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QbgPKxI2Jzfq"
      },
      "outputs": [],
      "source": [
        "def grid_search(ngpu, device, dataset, workers, \n",
        "                experiment_prefix, batch_size_list, shuffle_list, \n",
        "                num_epochs_list, loss_name_list, optimizer_name_list, \n",
        "                beta1_list, lr_list, momentums_list, plot, save_stats, create_dir\n",
        "                , save_epochs, save_models, manualSeed):\n",
        "\n",
        "    # all_stats = [] \n",
        "\n",
        "    # TO DO change for loops to zip \n",
        "    for batch_size in batch_size_list:\n",
        "        for shuffle in shuffle_list:\n",
        "            for num_epochs in num_epochs_list:\n",
        "                for loss_name in loss_name_list:\n",
        "\n",
        "                    iter_per_epoch_dis, iter_per_epoch_gen, grad_penalty_coef = set_loss_params(loss_name)\n",
        "                    for optimizer_name in optimizer_name_list:\n",
        "                        for beta1 in beta1_list:\n",
        "                            for lr in lr_list:\n",
        "                                for (momentumD, momentumG) in momentums_list : \n",
        "                                    lrD = lr\n",
        "                                    lrG = lr\n",
        "                                    # set seed before every experiment\n",
        "                                    set_seeds(manualSeed = manualSeed)\n",
        "\n",
        "                                    \n",
        "\n",
        "                                    print('====================PARAMETERS===================')\n",
        "                                    print('batch_size =', batch_size)\n",
        "                                    print('shuffle =', shuffle)\n",
        "                                    print('num_epoch =', num_epochs)\n",
        "                                    print('loss_name =', loss_name)\n",
        "                                    print('optimizer_name =', optimizer_name)\n",
        "                                    print('beta1 =', beta1)\n",
        "                                    print('lr =', lr)\n",
        "                                    print('iter_per_epoch_dis =', iter_per_epoch_dis)\n",
        "                                    print('iter_per_epoch_gen =', iter_per_epoch_gen)\n",
        "                                    print('grad_penalty_coef =', grad_penalty_coef)\n",
        "\n",
        "                                    stats, dataloader, netG, netD = run_experiment(ngpu, device, dataset, workers,\n",
        "                                                                                  batch_size, shuffle, num_epochs, plot, lrD, lrG, beta1, nz, \n",
        "                                                                                  loss_name, experiment_prefix, save_stats, create_dir, \n",
        "                                                                                  iter_per_epoch_dis, iter_per_epoch_gen, grad_penalty_coef, \n",
        "                                                                                  save_epochs, save_models, momentumD, momentumG, optimizer_name)\n",
        "\n",
        "    # all_stats.append(stats)\n",
        "    \n",
        "    return #all_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NTdcMZ4AtiVw"
      },
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "dataroot = PATH + \"data/\"\n",
        "\n",
        "# Dataset name\n",
        "dataset_name = 'mnist' # 'cifar10' or 'mnist'\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
        "image_size = 28 # 28 for mnist, 64 for others\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 128\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_repo_paths(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DRqoAVcKtC05"
      },
      "outputs": [],
      "source": [
        "dataset, nc = get_dataset(dataset_name, image_size, dataroot)\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEmdQBI_LFcW",
        "outputId": "e780fcb6-e77b-44bf-b914-5f02fba4471e"
      },
      "outputs": [],
      "source": [
        "grid_search(ngpu, device, dataset, workers,\n",
        "                        experiment_prefix = '', # and an extra word at the begining to the save path of the models and stats\n",
        "                        batch_size_list = [128],\n",
        "                        shuffle_list = [True],\n",
        "                        num_epochs_list = [300],\n",
        "                        loss_name_list = ['wass'], # wass, hinge\n",
        "                        optimizer_name_list = ['adam','wass','rmsprop'], # 'adam' 'sgd' 'rmsprop'\n",
        "                        beta1_list = [0.9], # 0.9 == default # Beta1 hyperparam for Adam optimizers\n",
        "                        lr_list = [1e-1,1e-2,1e-3,1e-4, 1e-5, 1e-6, 1e-7], # [1,1e-3,2e-4,1e-5,1e-6]\n",
        "                        momentums_list = [(0,0)], # [(momentumD, momentumG)]\n",
        "                        plot = False,\n",
        "                        save_stats = True, # save the stats to disk\n",
        "                        create_dir = True, # create the directories to save files\n",
        "                        save_epochs = 10, # save the model every save_epochs epochs\n",
        "                        save_models = True, # save the models to disk\n",
        "                        manualSeed = 123 # keep at 123\n",
        "                        ) # grad_penalty_coef"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beMBvkIjFl7z"
      },
      "source": [
        "# Training example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###########\n",
        " TO DO : run one training iteration with the examples and "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSQF8-Mitrs2"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeYrHwkRx-59"
      },
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "dataroot = PATH + \"data/\"\n",
        "\n",
        "# Dataset name\n",
        "dataset_name = 'mnist' # 'cifar10' or 'mnist'\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 128\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
        "image_size = 28 # 28 for mnist, 64 for others\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 128\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROhmdtOztq8W"
      },
      "outputs": [],
      "source": [
        "# Number of training epochs\n",
        "num_epochs = 3\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lrD = 2e-4\n",
        "lrG = 2e-4\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.9 # 0.9 == default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvDLoiTmyC8b"
      },
      "outputs": [],
      "source": [
        "dataset, nc = get_dataset(dataset_name, image_size, dataroot)\n",
        "\n",
        "# Create the dataloader\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "#print(dataset)\n",
        "#plot_img(dataloader, dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1rZFBRsvj-e"
      },
      "outputs": [],
      "source": [
        "loss_name = \"wass\" # wass, hinge\n",
        "iter_dis, iter_gen, grad_penalty_coef = 1, 1, 0.0\n",
        "\n",
        "if loss_name == \"wass\":\n",
        "    iter_dis, grad_penalty_coef = 5, 10.0\n",
        "\n",
        "netG = init_net(Generator(ngpu, nc, nz), device)\n",
        "print('Generator parameters', count_parameters(netG))\n",
        "\n",
        "netD = init_net(Discriminator(ngpu, nc, loss_name), device)\n",
        "print('Discriminator parameters', count_parameters(netD))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0wNXW77zD4b"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ-zyO5918Df"
      },
      "outputs": [],
      "source": [
        "fixed_noise, real_label, fake_label, optimizerD, optimizerG = init_optimizers(netD, netG, lrD, lrG, beta1, nz, device)\n",
        "experiment_prefix = '' # and extra word to add the automatically generate one if you really need it, ideally keep empty\n",
        "gan_training = Training(loss_name, netD, netG, device, real_label, fake_label, \n",
        "                        dataloader, num_epochs, fixed_noise, \n",
        "                        grad_penalty_coef, lrD, lrG, beta1, experiment_prefix, save_models, PATH, save_stats = True, create_dir=True,\n",
        "                        iter_per_epoch_dis=1, iter_per_epoch_gen=1, grad_penalty_coef=0.0)\n",
        "\n",
        "stats = gan_training.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhfcOvw-GTCX"
      },
      "outputs": [],
      "source": [
        "img_list = stats['img_list']\n",
        "G_losses = stats['G_losses']\n",
        "D_losses = stats['D_losses']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m pytorch_fid path/to/dataset1 path/to/dataset2 \n",
        "\n",
        "\n",
        "def bla(folderlist):\n",
        "    for item in folderlist:\n",
        "        !python -m pytorch_fid item[1] item[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-URPzv_TEhN7"
      },
      "source": [
        "# Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQ9voI50JsfC"
      },
      "outputs": [],
      "source": [
        "plot_loss(G_losses, D_losses, save = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrhkQ1fwJrJa"
      },
      "outputs": [],
      "source": [
        "plot_realvsfake(dataloader, device, img_list, save = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA4p6YNOEhN7"
      },
      "source": [
        "## G’s progression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI3SO9R1EhN7"
      },
      "outputs": [],
      "source": [
        "#%%capture\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaTJWVJPF1CQ"
      },
      "source": [
        "# Serialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSHhTbJGBDMS"
      },
      "outputs": [],
      "source": [
        "epoch = 999999999\n",
        "experiment_prefix = 'tteeesst'\n",
        "experiment_path, stats_path, models_path = generate_paths(PATH, experiment_prefix, loss_name, lrD, lrG, beta1, iter_dis, iter_gen, grad_penalty_coef, create_dir=True)\n",
        "save_path_G, save_path_D = model_paths(experiment_path, epoch, models_path)\n",
        "\n",
        "print(experiment_path)\n",
        "print(stats_path)\n",
        "print(save_path_G)\n",
        "print(save_path_D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OObYCZyxmO2a"
      },
      "outputs": [],
      "source": [
        "save_models(netG ,netD, save_path_G, save_path_D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nmoTYEInkMF"
      },
      "outputs": [],
      "source": [
        "pickle_save(stats, stats_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_MWpaCaKvxx"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "netD, netG = load_models(ngpu, Discriminator, Generator, save_path_G, save_path_D)\n",
        "\n",
        "stats = pickle_load(stats_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M21gaXFb05x8"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "dataroot = PATH + \"data/\"\n",
        "\n",
        "# Dataset name\n",
        "dataset_name = 'mnist' # 'cifar10' or 'mnist'\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
        "image_size = 28 # 28 for mnist, 64 for others\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 128\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1\n",
        "create_repo_paths(PATH)\n",
        "dataset, nc = get_dataset(dataset_name, image_size, dataroot)\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
            ")\n",
            "Discriminator(\n",
            "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "loss_name = 'wass'\n",
        "netG = init_net(Generator(ngpu, nc, nz), device)\n",
        "netD = init_net(Discriminator(ngpu, nc, loss_name), device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_gen_dataset(n_samples, batch_size, netG, nz, workers,shuffle=True):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      noise = torch.randn(n_samples, nz, 1, 1, device=device)\n",
        "      fake = netG(noise)\n",
        "\n",
        "    fake_dataset = torch.utils.data.TensorDataset(fake)\n",
        "    fake_dataloader = torch.utils.data.DataLoader(fake_dataset, batch_size=batch_size,\n",
        "                                         shuffle=shuffle, num_workers=workers)\n",
        "    return fake_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "xtDAYmuw04wd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Seed:  123\n"
          ]
        }
      ],
      "source": [
        "# Create the dataloader\n",
        "\n",
        "batch_size_eval = 10 # 128\n",
        "num_samples = 10 # 1000\n",
        "set_seeds(manualSeed=123)\n",
        "which = torch.ones(len(dataset)).multinomial(num_samples, replacement=True)\n",
        "dataset_subset = torch.utils.data.Subset(dataset, which)\n",
        "\n",
        "real_dataloader = torch.utils.data.DataLoader(dataset_subset, batch_size=batch_size_eval,\n",
        "                                         shuffle=False, num_workers=workers) # shuffle=False for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1ndW2gBr6dAm"
      },
      "outputs": [],
      "source": [
        "# Load inception model\n",
        "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
        "inception_model = InceptionV3([block_idx])\n",
        "inception_model = inception_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wG0cEgL71_6O"
      },
      "outputs": [],
      "source": [
        "# take first batch from the dataloader to get 500 samples :\n",
        "\n",
        "def calculate_fid(num_samples, real_dataloader, batch_size_eval, device, inception_model, netG, nz, workers):\n",
        "    with torch.no_grad():\n",
        "        # sample the generator (and output a dataset from that)\n",
        "        fake_dataloader = sample_gen_dataset(num_samples, batch_size_eval, netG, nz, workers, shuffle=True)\n",
        "\n",
        "        t_frechet = time.time()\n",
        "        frechet_dist = calculate_frechet(device, real_dataloader, fake_dataloader, inception_model) \n",
        "        print('frechet dist:', frechet_dist,'| time to calculate :',time.time()-t_frechet,'s')\n",
        "        \n",
        "    return frechet_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frechet dist: 397.35060522269424 | time to calculate : 11.557352542877197 s\n"
          ]
        }
      ],
      "source": [
        "# for i in range(5):\n",
        "# sample_batch = next(iter(dataloader))\n",
        "frechet_dist = calculate_fid(num_samples, real_dataloader, batch_size_eval, device, inception_model, netG, nz, workers)\n",
        "# print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
            ")\n",
            "Discriminator(\n",
            "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n",
            "Random Seed:  123\n"
          ]
        }
      ],
      "source": [
        "# Load inception model\n",
        "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
        "inception_model = InceptionV3([block_idx])\n",
        "inception_model = inception_model.to(device)\n",
        "\n",
        "# Init empty G and D\n",
        "netG = init_net(Generator(ngpu, nc, nz), device)\n",
        "netD = init_net(Discriminator(ngpu, nc, loss_name), device)\n",
        "\n",
        "# Init paths\n",
        "create_repo_paths(PATH)\n",
        "generated_data_path = PATH + 'generated_data/'\n",
        "generated_data_path \n",
        "\n",
        "# Create a sample of the mnist dataset\n",
        "batch_size_eval = 10 # 128\n",
        "num_samples = 10 # 1000\n",
        "set_seeds(manualSeed=123)\n",
        "which = torch.ones(len(dataset)).multinomial(num_samples, replacement=True)\n",
        "dataset_subset = torch.utils.data.Subset(dataset, which)\n",
        "\n",
        "real_dataloader = torch.utils.data.DataLoader(dataset_subset, batch_size=batch_size_eval,\n",
        "                                         shuffle=False, num_workers=workers) # shuffle=False for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_G(ngpu, Generator, save_path_G, device):\n",
        "\n",
        "    netG = init_net(Generator(ngpu, nc, nz), device)\n",
        "    netG.load_state_dict(torch.load(save_path_G),map_location=torch.device('cpu') )\n",
        "    netG.eval()\n",
        "    return netG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "./generated_data/adam_mG0_mD0_wassLoss_lrd0.01_lrg0.01_b1b0.9_itd5_itg1_gpv10.0_/models/model_G_0.zip\n",
            "Generator(\n",
            "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6716\\2888188414.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minner_folder_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/models/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[0mnet_G\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_G\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_folder_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/models/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6716\\1508317697.py\u001b[0m in \u001b[0;36mload_G\u001b[1;34m(ngpu, Generator, save_path_G, device)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnetG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnetG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path_G\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mnetG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnetG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    710\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    713\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m             \u001b[0mload_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m    999\u001b[0m         \u001b[1;31m# stop wrapping with _TypedStorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         loaded_storages[key] = torch.storage._TypedStorage(\n\u001b[1;32m-> 1001\u001b[1;33m             \u001b[0mwrap_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m             dtype=dtype)\n\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[0;32m    137\u001b[0m                            \u001b[1;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                            \u001b[1;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ],
      "source": [
        "walk_list = os.walk(generated_data_path)\n",
        "folder_list = next(walk_list)[1]\n",
        "calc_fid = True\n",
        "FID_list = []\n",
        "n_repitions = 1\n",
        "which_iterations = [0,50,100,150,200,250,290] \n",
        "# [0,10,20,30,40,50,60,70,80,90,100,110,120,\n",
        "# 130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290]\n",
        "desired_optimizer = 'sgd' # 'adam' 'rsmprop' 'sgd'\n",
        "desired_learning_rates = [1e-1,1e-2,1e-3,1e-4, 1e-5, 1e-6, 1e-7]\n",
        "\n",
        "\n",
        "for folder in tqdm(folder_list):\n",
        "    param_list = folder_list[0].split('_')\n",
        "    optimizer_name = param_list[0]\n",
        "    loss_name = param_list[3][:-4]\n",
        "    lr = param_list[4][3:]\n",
        "\n",
        "    # stats_path = generated_data_path + folder + '/stat.pickle'\n",
        "    # stats = pickle_load(stats_path)\n",
        "    # img_list = stats['img_list'] # 8x8 images fake generatred images in one picture\n",
        "    # G_losses = stats['G_losses'] \n",
        "    # D_losses = stats['D_losses'] \n",
        "    # img_list_nogrid  = stats['img_list_nogrid'] # 64 fake generatred images in a list\n",
        "    \n",
        "    inner_folder_path = generated_data_path+folder\n",
        "    for file in os.listdir(inner_folder_path+'/models/'):\n",
        "        model_type = file[:7]\n",
        "        if model_type == 'model_G':\n",
        "            number = int(file[8:-4])\n",
        "            if number in which_iterations:\n",
        "                print(number)\n",
        "                print(inner_folder_path+'/models/'+file)\n",
        "                net_G = load_G(ngpu, Generator, inner_folder_path+'/models/'+file,device)\n",
        "\n",
        "  \n",
        "    netD = init_net(Discriminator(ngpu, nc, loss_name), device)\n",
        "    netD.load_state_dict(torch.load(save_path_D))\n",
        "    netD.eval()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['models']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1/2 [00:00<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([3, 242, 242])\n",
            "./generated_data/adam_mG0_mD0_wassLoss_lrd0.01_lrg0.01_b1b0.9_itd5_itg1_gpv10.0_/stat.pickle\n",
            "<function model_paths at 0x000001C17674FF78>\n",
            "adam_mG0_mD0_wassLoss_lrd0.01_lrg0.01_b1b0.9_itd5_itg1_gpv10.0_\n",
            "['adam', 'mG0', 'mD0', 'wassLoss', 'lrd0.01', 'lrg0.01', 'b1b0.9', 'itd5', 'itg1', 'gpv10.0', '']\n",
            "optimizer_name: adam\n",
            "momentumG: 0\n",
            "momentD: 0\n",
            "loss_name: wass\n",
            "lrd: 0.01\n",
            "lrg: 0.01\n",
            "beta1_val: 0.9\n",
            "iteration_dis: 5\n",
            "iteration_gen: 1\n",
            "gradient_penalty 10.0\n",
            "['models']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread QueueFeederThread:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\multiprocessing\\queues.py\", line 232, in _feed\n",
            "    close()\n",
            "  File \"c:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\multiprocessing\\connection.py\", line 177, in close\n",
            "    self._close()\n",
            "  File \"c:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\multiprocessing\\connection.py\", line 277, in _close\n",
            "    _CloseHandle(self._handle)\n",
            "OSError: [WinError 6] The handle is invalid\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"c:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"c:\\Users\\Younes\\.conda\\envs\\optmlgan\\lib\\multiprocessing\\queues.py\", line 263, in _feed\n",
            "    queue_sem.release()\n",
            "ValueError: semaphore or lock released too many times\n",
            "\n",
            "100%|██████████| 2/2 [00:05<00:00,  3.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([3, 242, 242])\n",
            "./generated_data/adam_mG0_mD0_wassLoss_lrd0.1_lrg0.1_b1b0.9_itd5_itg1_gpv10.0_/stat.pickle\n",
            "<function model_paths at 0x000001C17674FF78>\n",
            "adam_mG0_mD0_wassLoss_lrd0.1_lrg0.1_b1b0.9_itd5_itg1_gpv10.0_\n",
            "['adam', 'mG0', 'mD0', 'wassLoss', 'lrd0.01', 'lrg0.01', 'b1b0.9', 'itd5', 'itg1', 'gpv10.0', '']\n",
            "optimizer_name: adam\n",
            "momentumG: 0\n",
            "momentD: 0\n",
            "loss_name: wass\n",
            "lrd: 0.01\n",
            "lrg: 0.01\n",
            "beta1_val: 0.9\n",
            "iteration_dis: 5\n",
            "iteration_gen: 1\n",
            "gradient_penalty 10.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "walk_list = os.walk(generated_data_path)\n",
        "folder_list = next(walk_list)[1]\n",
        "calc_fid = True\n",
        "FID_list = []\n",
        "n_repitions = 1\n",
        "\n",
        "for folder in tqdm(folder_list):\n",
        "    print(generated_data_path+folder[0])\n",
        "    walk_list_2 = os.walk(generated_data_path+folder[0])\n",
        "    folder_list_2 = next(walk_list_2)[1]\n",
        "    print(folder_list_2)\n",
        "    param_list = folder_list[0].split('_')\n",
        "\n",
        "    optimizer_name = param_list[0]\n",
        "    momentumG = param_list[1][2:]\n",
        "    momentD = param_list[2][2:]\n",
        "    loss_name = param_list[3][:-4]\n",
        "    lrd = param_list[4][3:]\n",
        "    lrg = param_list[5][3:]\n",
        "    beta1_val = param_list[6][3:]\n",
        "    iteration_dis = param_list[7][3:]\n",
        "    iteration_gen = param_list[8][3:]\n",
        "    gradient_penalty_val = param_list[9][3:]\n",
        "    stats_path = generated_data_path + folder + '/stat.pickle'\n",
        "    params = [optimizer_name, momentumG, momentD, loss_name, lrd, \n",
        "                lrg, beta1_val, iteration_dis, iteration_gen, \n",
        "                gradient_penalty_val, stats_path]\n",
        "    stats = pickle_load(stats_path)\n",
        "\n",
        "    img_list = stats['img_list'] # 8x8 images fake generatred images in one picture\n",
        "    G_losses = stats['G_losses'] \n",
        "    D_losses = stats['D_losses'] \n",
        "    img_list_nogrid  = stats['img_list_nogrid'] # 64 fake generatred images in a list\n",
        "\n",
        "    # netG = \n",
        "    # if calc_fid:\n",
        "    #     fid_list = []\n",
        "    #     for i in range(n_repitions):\n",
        "    #             frechet_dist = calculate_fid(num_samples, real_dataloader, batch_size_eval, \n",
        "    #             device, inception_model, netG, nz, workers)\n",
        "    #             fid_list.append(frechet_dist)\n",
        "\n",
        "    model_paths_ = generated_data_path + '/models'\n",
        "    # debug prints\n",
        "    print(img_list_nogrid[0].shape)\n",
        "    print(img_list[0].shape)\n",
        "    print(stats_path)\n",
        "    print(model_paths)\n",
        "    print(folder)\n",
        "    print(param_list)\n",
        "    print('optimizer_name:', optimizer_name)\n",
        "    print('momentumG:', momentumG)\n",
        "    print('momentD:', momentD)\n",
        "    print('loss_name:', loss_name)\n",
        "    print('lrd:', lrd)\n",
        "    print('lrg:', lrg)\n",
        "    print('beta1_val:', beta1_val)\n",
        "    print('iteration_dis:', iteration_dis)\n",
        "    print('iteration_gen:', iteration_gen)\n",
        "    print('gradient_penalty', gradient_penalty_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTdcMZ4AtiVw"
      },
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "dataroot = PATH + \"data/\"\n",
        "\n",
        "# Dataset name\n",
        "dataset_name = 'mnist' # 'cifar10' or 'mnist'\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
        "image_size = 28 # 28 for mnist, 64 for others\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 128\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_repo_paths(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRqoAVcKtC05"
      },
      "outputs": [],
      "source": [
        "dataset, nc = get_dataset(dataset_name, image_size, dataroot)\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./generated_data/\n",
            "['adam_mG0_mD0_wassLoss_lrd0.01_lrg0.01_b1b0.9_itd5_itg1_gpv10.0_', 'adam_mG0_mD0_wassLoss_lrd0.1_lrg0.1_b1b0.9_itd5_itg1_gpv10.0_']\n",
            "['ReadMe.md']\n",
            "_____\n",
            "./generated_data/adam_mG0_mD0_wassLoss_lrd0.01_lrg0.01_b1b0.9_itd5_itg1_gpv10.0_\n",
            "['models']\n",
            "['stat.pickle']\n",
            "_____\n",
            "./generated_data/adam_mG0_mD0_wassLoss_lrd0.01_lrg0.01_b1b0.9_itd5_itg1_gpv10.0_\\models\n",
            "[]\n",
            "['model_D_0.zip', 'model_D_10.zip', 'model_D_20.zip']\n",
            "_____\n",
            "./generated_data/adam_mG0_mD0_wassLoss_lrd0.1_lrg0.1_b1b0.9_itd5_itg1_gpv10.0_\n",
            "['models']\n",
            "['stat.pickle']\n",
            "_____\n",
            "./generated_data/adam_mG0_mD0_wassLoss_lrd0.1_lrg0.1_b1b0.9_itd5_itg1_gpv10.0_\\models\n",
            "[]\n",
            "['model_D_0.zip', 'model_D_10.zip', 'model_D_20.zip']\n",
            "_____\n"
          ]
        }
      ],
      "source": [
        "for a,b,c in os.walk(generated_data_path):\n",
        "    print(a)\n",
        "    print(b)\n",
        "    print(c)\n",
        "    print('_____')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-URPzv_TEhN7"
      ],
      "include_colab_link": true,
      "name": "dcgan.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('optmlgan')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "6a6457a5aade1d7f0f784b93b9d1e5b6320a7fcf78907f3f0ade3d2c3999d686"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
