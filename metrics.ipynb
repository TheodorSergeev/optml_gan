{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheodorSergeev/optml_gan/blob/main/dcgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fe1zK4TEn2P"
      },
      "source": [
        "Adapted from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElE3epO2FCLq"
      },
      "source": [
        "# Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg1MBmvsdWEd",
        "outputId": "2c66a80f-d454-420c-e9ab-24b361acc456"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # packages to generate requirement.txt\n",
        "    %pip install nbconvert\n",
        "    %pip install pipreqs\n",
        "    # for Frechet inception distance\n",
        "    %pip install pytorch-fid\n",
        "\n",
        "    %cd drive/My Drive/optml_gan2\n",
        "    PATH = './'\n",
        "else:\n",
        "    PATH = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M50Mkga4EhNy"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.utils.data\n",
        "\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from scipy import linalg\n",
        "from torch.nn.functional import adaptive_avg_pool2d\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqmZqleaEhN0"
      },
      "source": [
        "# Source code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.data_handling import *\n",
        "from src.utils import *\n",
        "from src.model import *\n",
        "from src.losses import *\n",
        "from src.fid import *\n",
        "\n",
        "loss_dict = {\n",
        "    \"kl\": (loss_dis_kl, loss_gen_kl),\n",
        "    \"wass\": (loss_dis_wasser, loss_gen_wasser),\n",
        "    \"hinge\": (loss_dis_hinge, loss_gen_hinge)\n",
        "}\n",
        "\n",
        "# FID\n",
        "\n",
        "from src.training import *\n",
        "from src.visualisation import *\n",
        "from src.serialisation import *\n",
        "\n",
        "# https://keras.io/examples/generative/conditional_gan/\n",
        "from src.architectures import *\n",
        "\n",
        "from src.gridsearch import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M21gaXFb05x8"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "dataroot = PATH + \"data/\"\n",
        "\n",
        "# Dataset name\n",
        "dataset_name = 'mnist' # 'cifar10' or 'mnist'\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 0\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
        "image_size = 28 # 28 for mnist, 64 for others\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 128\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1\n",
        "create_repo_paths(PATH)\n",
        "dataset, nc = get_dataset(dataset_name, image_size, dataroot)\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "xtDAYmuw04wd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Seed:  123\n"
          ]
        }
      ],
      "source": [
        "# Create the dataloader\n",
        "\n",
        "batch_size_eval = 32 # 128\n",
        "num_samples = 64 # 1000\n",
        "set_seeds(manualSeed=123)\n",
        "which = torch.ones(len(dataset)).multinomial(num_samples, replacement=True)\n",
        "dataset_subset = torch.utils.data.Subset(dataset, which)\n",
        "\n",
        "real_dataloader = torch.utils.data.DataLoader(dataset_subset, batch_size=batch_size_eval,\n",
        "                                         shuffle=False, num_workers=workers) # shuffle=False for reproducibility\n",
        "                                         \n",
        "# Load inception model\n",
        "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
        "inception_model = InceptionV3([block_idx])\n",
        "inception_model = inception_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_name = 'wass'\n",
        "netG = init_net(Generator(ngpu, nc, nz), device, ngpu)\n",
        "netD = init_net(Discriminator(ngpu, nc, loss_name), device, ngpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wG0cEgL71_6O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:06<00:00,  4.83it/s]\n",
            "100%|██████████| 32/32 [00:05<00:00,  5.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frechet dist: 365.0568528083575 | time to calculate : 24.826169967651367 s\n"
          ]
        }
      ],
      "source": [
        "# for i in range(5):\n",
        "# sample_batch = next(iter(dataloader))\n",
        "frechet_dist = calculate_fid(num_samples, real_dataloader, batch_size_eval, device, inception_model, netG, nz, workers)\n",
        "# print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
            ")\n",
            "Discriminator(\n",
            "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n",
            "Random Seed:  123\n"
          ]
        }
      ],
      "source": [
        "# Load inception model\n",
        "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
        "inception_model = InceptionV3([block_idx])\n",
        "inception_model = inception_model.to(device)\n",
        "\n",
        "# Init empty G and D\n",
        "netG = init_net(Generator(ngpu, nc, nz), device, ngpu)\n",
        "netD = init_net(Discriminator(ngpu, nc, loss_name), device, ngpu)\n",
        "\n",
        "# Init paths\n",
        "create_repo_paths(PATH)\n",
        "generated_data_path = PATH + 'generated_data/'\n",
        "generated_data_path \n",
        "\n",
        "# Create a sample of the mnist dataset\n",
        "batch_size_eval = 10 # 128\n",
        "num_samples = 10 # 1000\n",
        "set_seeds(manualSeed=123)\n",
        "which = torch.ones(len(dataset)).multinomial(num_samples, replacement=True)\n",
        "dataset_subset = torch.utils.data.Subset(dataset, which)\n",
        "\n",
        "real_dataloader = torch.utils.data.DataLoader(dataset_subset, batch_size=batch_size_eval,\n",
        "                                         shuffle=False, num_workers=workers) # shuffle=False for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_G(ngpu, Generator, save_path_G, device):\n",
        "\n",
        "    netG = init_net(Generator(ngpu, nc, nz), device,ngpu)\n",
        "    netG.load_state_dict(torch.load(save_path_G))\n",
        "    netG.eval()\n",
        "    return netG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rmsprop_mG0_mD0_wassLoss_lrd0.0001_lrg0.0001_b1b0.9_itd5_itg1_gpv10.0_\n",
            "rmsprop 0.0001\n",
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  5.16it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frechet dist: 375.0156716629199 | time to calculate : 9.843644380569458 s\n",
            "100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  5.37it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frechet dist: 375.7824242718262 | time to calculate : 9.964108228683472 s\n",
            "50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  5.35it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frechet dist: 376.8077026061756 | time to calculate : 10.002908945083618 s\n",
            "rmsprop_mG0_mD0_wassLoss_lrd0.001_lrg0.001_b1b0.9_itd5_itg1_gpv10.0_\n",
            "rmsprop 0.001\n",
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  5.34it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frechet dist: 378.0283057411398 | time to calculate : 10.097379207611084 s\n",
            "100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  4.93it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frechet dist: 376.1479737473754 | time to calculate : 10.048278570175171 s\n",
            "50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  5.30it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frechet dist: 375.83017605963806 | time to calculate : 9.873766422271729 s\n",
            "rmsprop_mG0_mD0_wassLoss_lrd0.01_lrg0.01_b1b0.9_itd5_itg1_gpv10.0_\n",
            "rmsprop 0.01\n",
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  5.34it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frechet dist: 376.31020434258375 | time to calculate : 9.776933193206787 s\n",
            "100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  5.27it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frechet dist: 374.7157998532318 | time to calculate : 9.813695669174194 s\n",
            "50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  4.94it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frechet dist: 377.2082279357388 | time to calculate : 9.87267255783081 s\n"
          ]
        }
      ],
      "source": [
        "list_subfolders_with_paths = sorted([f.path for f in os.scandir(generated_data_path) if f.is_dir()])\n",
        "\n",
        "paths_adam = list_subfolders_with_paths[0:7]\n",
        "paths_rmsprop = list_subfolders_with_paths[7:14]\n",
        "paths_sgd = list_subfolders_with_paths[14:]\n",
        "\n",
        "# print( paths_adam)\n",
        "# print( paths_rmsprop)\n",
        "# print( paths_sgd)\n",
        "\n",
        "which_iterations = [0,50,100] #[0,50,100,150,200,250,290] # [0,10,20,30,40,50,60,70,80,90,100,110,120, 130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290]\n",
        "# desired_learning_rates = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7] # [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
        "list_paths = paths_rmsprop # paths_adam paths_sgd paths_rmsprop\n",
        "\n",
        "all_optimizer_scores = {}\n",
        "fix_extension = False\n",
        "calculate_frechet_bool = True\n",
        "\n",
        "all_lr_scores = {}\n",
        "get_stats = True\n",
        "# all_scores['adam'] = [desired_learning_rates, score_list]\n",
        "\n",
        "for path in list_paths:\n",
        "    folder = path[17:]\n",
        "    print(folder)\n",
        "    param_list = folder.split('_')\n",
        "\n",
        "    optimizer_name = param_list[0]\n",
        "    loss_name = param_list[3][:-4]\n",
        "    lr = param_list[4][3:]\n",
        "    # print()\n",
        "    print(optimizer_name, lr)\n",
        "    score_list = []\n",
        "    if get_stats:\n",
        "        stats_path = path + '/stat.pickle'\n",
        "        stats = pickle_load(stats_path)\n",
        "        img_list = stats['img_list'] # 8x8 images fake generatred images in one picture\n",
        "        G_losses = stats['G_losses'] \n",
        "        D_losses = stats['D_losses'] \n",
        "        img_list_nogrid  = stats['img_list_nogrid'] # 64 fake generatred images in a list\n",
        "    else:\n",
        "        for file in os.listdir(path+'/models/'):\n",
        "            # print(file[:7])\n",
        "                if file[:7] == 'model_G':\n",
        "                    # print(file)\n",
        "                    number = int(file[8:].split('.')[0]) # split because sometimes file has extension .zip sometimes doesn't\n",
        "                    # print(number)\n",
        "                    if number in which_iterations: # epochs\n",
        "                        # score_list[float(lr)] = number\n",
        "                        \n",
        "                        print(number)\n",
        "                        # print(path+'/models/'+file)\n",
        "                        # print(len(file[8:].split('.')))\n",
        "\n",
        "                        if fix_extension: # if files are not in .zip extension, use this\n",
        "                            if len(file[8:].split('.'))==1: \n",
        "                                print(path+'/models/'+file)\n",
        "                                os.rename(path+'/models/'+file, path+'/models/'+file+'.zip') \n",
        "\n",
        "                        if calculate_frechet_bool:\n",
        "                            net_G = load_G(ngpu, Generator, path+'/models/'+file,device)\n",
        "                            frechet_dist = calculate_fid(num_samples, real_dataloader, batch_size_eval, device, inception_model, netG, nz, workers)\n",
        "                            score_list.append(frechet_dist)\n",
        "    all_lr_scores[float(lr)] = score_list\n",
        "all_optimizer_scores[optimizer_name] = all_lr_scores\n",
        "all_optimizer_stats[optimizer_name]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-URPzv_TEhN7"
      ],
      "include_colab_link": true,
      "name": "dcgan.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('optmlgan')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "6a6457a5aade1d7f0f784b93b9d1e5b6320a7fcf78907f3f0ade3d2c3999d686"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
